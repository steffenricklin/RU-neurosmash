{"cells":[{"cell_type":"markdown","source":"# Convolutional Auto-Encoder","metadata":{"deepnote_cell_type":"markdown","cell_id":"00000-89420bb6-4667-4bfe-8da6-28fbf547e761"}},{"cell_type":"code","metadata":{"deepnote_cell_type":"code","cell_id":"00001-27162a39-c57b-43ca-8b46-2727acc9eb7b","output_cleared":false,"source_hash":"b09e5c83","execution_millis":0,"execution_start":1605636226302},"source":"# Imports\n#!pip install mxnet\nfrom convvae import ConvVae\nimport numpy as np\nimport PIL\nimport mxnet as mx\nfrom mxnet import nd, autograd, gluon\nfrom mxnet.gluon import nn\nfrom sklearn.model_selection import train_test_split\n# !pip install tqdm\nfrom tqdm import tqdm, tqdm_notebook","execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"deepnote_cell_type":"code","tags":[],"cell_id":"00002-a7f4647d-f5ac-4848-aefa-56e6dd563f8c","output_cleared":false,"source_hash":"49e4ee99","execution_millis":1,"execution_start":1605636353128},"source":"import Neurosmash\n\n# These are the default environment arguments. They must be the same as the values that are set in the environment GUI.\nip         = \"127.0.0.1\" # Ip address that the TCP/IP interface listens to (127.0.0.1 by default)\nport       = 13000       # Port number that the TCP/IP interface listens to (13000 by default)\n\n# This is the size of the texture that the environment is rendered.\n# This is set to 784 by default, which will result in a crisp image but slow speed.\n# You can change the size to a value that works well for your environment but should not go too low.\nsize       = 64 # 96, 192\n\n# This is the simulation speed of the environment. This is set to 1 by default.\n# Setting it to n will make the simulation n times faster.\n# In other words, less (if n < 1) or more (if n > 1) simulation time will pass per step.\n# You might want to increase this value to around 10 if you cannot train your models fast enough\n# so that they can sample more states in a shorter number of steps at the expense of precision.\ntimescale  = 5\n\n# This is an example agent.\n# It has a step function, which gets reward/state as arguments and returns an action.\n# Right now, it always outputs a random action (3) regardless of reward/state.\n# The real agent should output one of the following three actions:\n# none (0), left (1) and right (2)\nagent = Neurosmash.Agent() \n\n# This is the main environment.\n# It has a reset function, which is used to reset the environment before episodes.\n# It also has a step function, which is used to which steps one time point\n# It gets an action (as defined above) as input and outputs the following:\n# end (true if the episode has ended, false otherwise)\n# reward (10 if won, 0 otherwise)\n# state (flattened size x size x 3 vector of pixel values)\n# The state can be converted into an image as follows:\n# image = np.array(state, \"uint8\").reshape(size, size, 3)\n# You can also use to Neurosmash.Environment.state2image(state) function which returns\n# the state as a PIL image\nenvironment = Neurosmash.Environment(ip, port, size, timescale)\n\n","execution_count":12,"outputs":[{"output_type":"error","ename":"ConnectionRefusedError","evalue":"[Errno 111] Connection refused","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-89757b8cf8cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;31m# You can also use to Neurosmash.Environment.state2image(state) function which returns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m# the state as a PIL image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0menvironment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNeurosmash\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEnvironment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimescale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/work/RU-neurosmash/vae/Neurosmash.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, ip, port, size, timescale)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimescale\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mtimescale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 111] Connection refused"]}]},{"cell_type":"code","metadata":{"deepnote_cell_type":"code","tags":[],"cell_id":"00003-f715da44-dc77-493c-a2e8-16ee7023683a"},"source":"# The following steps through an entire episode from start to finish with random actions (by default)\n\nend, reward, state = environment.reset()\nnr_images = 100\nshape = np.array(state).reshape((3, size,size)).shape\nimages = np.zeros((nr_images, shape[0], shape[1], shape[2]))\n\ni = 0\nwhile i < nr_images:\n    end, reward, state = environment.reset()\n    while (end == 0):\n        action = agent.step(end, reward, state)\n        end, reward, state = environment.step(action)\n        images[i] = np.array(state).reshape(shape)\n        i += 1\n        if i >= nr_images:\n            end = 1\n\n    # Let's run it a few more steps so that the things have time to settle down\n    for _ in range(100):\n        if i >= nr_images:\n            continue\n        action = agent.step(end, reward, state)\n        end, reward, state = environment.step(action)\n        images[i] = np.array(state).reshape(shape)\n        i += 1\n\nenvironment.state2image(state)","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"deepnote_cell_type":"code","tags":[],"cell_id":"00004-882c3f59-c6b5-4e03-98be-eceef2911084","output_cleared":false,"source_hash":"1aafe3e7","execution_start":1605635893842,"execution_millis":0},"source":"batch_size = 100\ntrain_data, test_data = train_test_split(images, test_size=0.33, random_state=42)\n\ntrain_iter = mx.io.NDArrayIter(data={'data': train_data}, batch_size = batch_size)\ntest_iter = mx.io.NDArrayIter(data={'data': test_data}, batch_size = batch_size)\n\nvae = ConvVae()\n#vae.initialize(ctx=vae.ctx) # Initialising weights\nvae.collect_params().initialize(mx.init.Xavier(), ctx=vae.ctx)\nvae.hybridize()  # activates hybrid-mode of the Hybrid-Block\ntrainer = gluon.Trainer(vae.collect_params(), 'adam', {'learning_rate': .001}) ","execution_count":6,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'images' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-07a5faa784e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.33\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrain_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNDArrayIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtest_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNDArrayIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'images' is not defined"]}]},{"cell_type":"code","metadata":{"deepnote_cell_type":"code","tags":[],"cell_id":"00004-8f475e7b-0ea8-4cd4-863d-5d66f0c87543"},"source":"def train_vae(n_epochs=50):\n    train_loss = []\n    valid_loss = []\n\n    for epoch in tqdm_notebook(range(n_epochs), desc='epochs'):\n        \n        # \n        train_iter.reset()\n        test_iter.reset()\n\n        # Training data\n        n_batch_train = 0\n        for batch in train_iter:\n            n_batch_train += 1\n            data = batch.data[0].as_in_context(ctx)\n            with autograd.record():\n                y = vae(data)\n            KL = 0.5 * F.sum(1 + vae.lv - vae.mu * vae.mu - F.exp(lv), axis=1)\n            logloss = F.sum(data*F.log(y+self.soft_zero)+ (1-data)*F.log(1-y+self.soft_zero), axis=1)\n            loss = -logloss-KL\n            loss.backward()\n            trainer.step(data.shape[0])\n            epoch_loss += nd.mean(loss).asscalar()\n\n        # Validation data\n        n_batch_val = 0\n        for batch in test_iter:\n            n_batch_val += 1\n            data = batch.data[0].as_in_context(ctx)\n            loss = vae(data)\n            epoch_val_loss += nd.mean(loss).asscalar()\n\n        epoch_loss /= n_batch_train\n        epoch_val_loss /= n_batch_val\n\n        training_loss.append(epoch_loss)\n        validation_loss.append(epoch_val_loss)\n\n        if epoch % max(print_period,1) == 0:\n            tqdm.write('Epoch{}, Training loss {:.2f}, Validation loss {:.2f}'.format(epoch, epoch_loss, epoch_val_loss))\n\n        ","execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_vae(1)","metadata":{"deepnote_cell_type":"code","tags":[],"cell_id":"00006-e87be96e-cd33-4b5b-ad86-3d3060eb5020"},"outputs":[],"execution_count":null}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3-final"},"orig_nbformat":2,"kernelspec":{"name":"python3","display_name":"Python 3"},"deepnote_notebook_id":"d560aee3-cb13-400a-9cbc-b5a7d67e48fb","deepnote_execution_queue":[]}}